{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kZ11UN4iWNzW"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U transformers peft accelerate optimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKD0HY8eWTOQ",
        "outputId": "a7ffc3b4-dfa1-4c8e-b03d-775f13011693"
      },
      "outputs": [],
      "source": [
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu117/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1kuySlGpdoz",
        "outputId": "681750f5-8c78-4508-fb0d-beeba91acafa"
      },
      "outputs": [],
      "source": [
        "pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k6156OF7H49n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-26T19:45:45.587207Z",
          "iopub.status.busy": "2023-11-26T19:45:45.586647Z",
          "iopub.status.idle": "2023-11-26T19:45:45.598118Z",
          "shell.execute_reply": "2023-11-26T19:45:45.597251Z",
          "shell.execute_reply.started": "2023-11-26T19:45:45.587172Z"
        },
        "id": "QFcu8MYWJDE_",
        "outputId": "3bc963a8-1254-44ed-be03-e7938201462e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': 'Fingerprint Security Lock', 'output': ['Brainstormed on a security system to be guarded by fingerprints using an AS608 fingerprint sensor', 'Implemented this model using an Arduino UNO Breakout board along with a Relay Module.']}\n",
            "{'input': 'Lego Image Classifier - Computer Vision, Self Project', 'output': ['Built a multi-class classifier with Keras, which can classify Lego images into 16 distinct classes using state of the art VGG16 algorithm, achieving 95% training accuracy', 'Given data was a folder containing 4500 images and a CSV file with respective class labels. Using Python, segregated them into 16 folders with each type of Lego to feed to CNN']}\n"
          ]
        }
      ],
      "source": [
        "# Open and load the content of the Train_dataset.json file into Train_data\n",
        "with open(\"/content/Train_dataset.json\") as json_file:\n",
        "    Train_data = json.load(json_file)\n",
        "\n",
        "# Open and load the content of the Valid_dataset.json file into Validation_data\n",
        "with open(\"/content/Valid_dataset.json\") as json_file:\n",
        "    Validation_data = json.load(json_file)\n",
        "\n",
        "# Print the first element of Train_data and Validation_data\n",
        "print(Train_data[0])\n",
        "print(Validation_data[0])\n",
        "\n",
        "# Convert Train_data and Validation_data into pandas Series\n",
        "Train_data = pd.Series(Train_data)\n",
        "Validation_data = pd.Series(Validation_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YBgH76jaD6-w"
      },
      "outputs": [],
      "source": [
        "def formatting_func(example):\n",
        "    text = f\"\"\"<s>[INST] <<SYS>> Answer the question based on the question below, you are a helpful resume points generator.\n",
        "        [Question]: {example['input']}\n",
        "        ### [Answer]: {example['output']} [\\INST]\"\"\"\n",
        "\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC14Vxs2Q3Xi",
        "outputId": "9131ebf4-8c4b-4972-bf7e-eaa166cf763d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
            "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. use_exllama, exllama_config, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n",
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda:CUDA extension not installed.\n",
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda_old:CUDA extension not installed.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules from transformers library\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GPTQConfig\n",
        "\n",
        "# Define quantization configuration with 4 bits and disabling exllama\n",
        "quantization_config_loading = GPTQConfig(bits=4, disable_exllama=True)\n",
        "\n",
        "# Specify the model name or path and the model basename\n",
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
        "model_basename = \"model\"\n",
        "\n",
        "# Load the pre-trained model for causal language modeling\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    revision=\"gptq-4bit-32g-actorder_True\",\n",
        "    use_safetensors=True,\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=quantization_config_loading,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Disable caching in the model configuration\n",
        "model.config.use_cache = False\n",
        "\n",
        "# Load the tokenizer for the specified model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    padding_side=\"left\",\n",
        "    add_eos_token=True,\n",
        "    add_bos_token=True\n",
        ")\n",
        "\n",
        "# Set the pad_token to be the same as the eos_token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Define a function to generate and tokenize a prompt using a formatting function\n",
        "def generate_and_tokenize_prompt(prompt):\n",
        "    return tokenizer(formatting_func(prompt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T20:09:41.282254Z",
          "iopub.status.busy": "2023-11-26T20:09:41.281834Z",
          "iopub.status.idle": "2023-11-26T20:09:41.342817Z",
          "shell.execute_reply": "2023-11-26T20:09:41.342090Z",
          "shell.execute_reply.started": "2023-11-26T20:09:41.282221Z"
        },
        "id": "sZLbrUqgJDFC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "tokenised_Train_dataset = Train_data.map(generate_and_tokenize_prompt)\n",
        "tokenised_valid_dataset = Validation_data.map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "execution": {
          "iopub.execute_input": "2023-11-26T20:10:23.360179Z",
          "iopub.status.busy": "2023-11-26T20:10:23.359361Z",
          "iopub.status.idle": "2023-11-26T20:10:23.672512Z",
          "shell.execute_reply": "2023-11-26T20:10:23.671664Z",
          "shell.execute_reply.started": "2023-11-26T20:10:23.360136Z"
        },
        "id": "miPPI3VWJDFC",
        "outputId": "cef7be4d-8f27-4272-b781-6141ccd050e0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "619\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
        "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
        "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
        "    print(len(lengths))\n",
        "\n",
        "    # Plotting the histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
        "    plt.xlabel('Length of input_ids')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Lengths of input_ids')\n",
        "    plt.show()\n",
        "\n",
        "plot_data_lengths(tokenised_Train_dataset, tokenised_valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T20:12:59.296788Z",
          "iopub.status.busy": "2023-11-26T20:12:59.296040Z",
          "iopub.status.idle": "2023-11-26T20:12:59.300915Z",
          "shell.execute_reply": "2023-11-26T20:12:59.299918Z",
          "shell.execute_reply.started": "2023-11-26T20:12:59.296749Z"
        },
        "id": "VGRnIZ4vJDFC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "max_length = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T20:13:03.044396Z",
          "iopub.status.busy": "2023-11-26T20:13:03.043325Z",
          "iopub.status.idle": "2023-11-26T20:13:03.050291Z",
          "shell.execute_reply": "2023-11-26T20:13:03.049257Z",
          "shell.execute_reply.started": "2023-11-26T20:13:03.044348Z"
        },
        "id": "qCYq_XcHJDFC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define a function to generate and tokenize a prompt using the tokenizer\n",
        "def generate_and_tokenize_prompt2(prompt):\n",
        "    # Tokenize the prompt using the specified formatting function and additional configurations\n",
        "    result = tokenizer(\n",
        "        formatting_func(prompt),\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    # Copy input_ids to labels in the result dictionary\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "\n",
        "    # Return the result\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T20:13:50.884092Z",
          "iopub.status.busy": "2023-11-26T20:13:50.883687Z",
          "iopub.status.idle": "2023-11-26T20:13:50.947144Z",
          "shell.execute_reply": "2023-11-26T20:13:50.946375Z",
          "shell.execute_reply.started": "2023-11-26T20:13:50.884059Z"
        },
        "id": "4gzLS4XpJDFC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset = Train_data.map(generate_and_tokenize_prompt2)\n",
        "tokenized_val_dataset = Validation_data.map(generate_and_tokenize_prompt2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "execution": {
          "iopub.execute_input": "2023-11-26T20:14:09.593029Z",
          "iopub.status.busy": "2023-11-26T20:14:09.592642Z",
          "iopub.status.idle": "2023-11-26T20:14:09.897218Z",
          "shell.execute_reply": "2023-11-26T20:14:09.896245Z",
          "shell.execute_reply.started": "2023-11-26T20:14:09.592996Z"
        },
        "id": "gpLbKl4lJDFC",
        "outputId": "4db0f9f6-1297-408b-a007-4e0d8eb5592f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "619\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUPsy3t1JDFD"
      },
      "source": [
        "Pre_Training Eval Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T20:15:38.325375Z",
          "iopub.status.busy": "2023-11-26T20:15:38.324974Z",
          "iopub.status.idle": "2023-11-26T20:15:38.329934Z",
          "shell.execute_reply": "2023-11-26T20:15:38.329022Z",
          "shell.execute_reply.started": "2023-11-26T20:15:38.325345Z"
        },
        "id": "kDg19xqNJDFD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "eval_prompt = \"write some resume points on mars roverteam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-26T20:17:57.730095Z",
          "iopub.status.busy": "2023-11-26T20:17:57.729717Z",
          "iopub.status.idle": "2023-11-26T20:18:58.442677Z",
          "shell.execute_reply": "2023-11-26T20:18:58.441746Z",
          "shell.execute_reply.started": "2023-11-26T20:17:57.730066Z"
        },
        "id": "aHPA-SEQJDFE",
        "outputId": "9fa481ff-e13b-44b1-ae35-21d5704bb0fe",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "write some resume points on mars roverteam did it world do a job do the most its best have Is it do an issue do a better can use do fix make see it best free 1 can say you can write a fixed the world 2  can give a rest 7  had 9 5  a  pre  and  a new  a  who  a  it a  to give a disc the same the other need a new a price a wait a well it is not available that we could take a rest was not available but it was only a very it hard it a \"s a ' it a ' would you a ' it ' it ' a ' it ' it ' a ' it a ' it a ' it a ' but it a ' were does it a fact did you can show it a 's ' did a ' it ' ' it ' ' a ' ' a ' ' a ' ' a ' etc ' a ' did a ' it a ' did a ' a sp it a ' did a ' a ' a ' a ' did a ' a ' a ' a ' a p a a world a a a p a a disc a a a world a a a a world a a a a a can write a a a a can a could\n"
          ]
        }
      ],
      "source": [
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mEa9IzU7MAPX"
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DdaBnVM2MMCT"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-26T20:19:46.492301Z",
          "iopub.status.busy": "2023-11-26T20:19:46.491916Z",
          "iopub.status.idle": "2023-11-26T20:19:46.707647Z",
          "shell.execute_reply": "2023-11-26T20:19:46.706316Z",
          "shell.execute_reply.started": "2023-11-26T20:19:46.492271Z"
        },
        "id": "fdQPOO46JDFE",
        "outputId": "33170892-b85e-4198-8fe1-35dcdf03fb59",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 63180800 || all params: 391275520 || trainable%: 16.147394040904988\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# We want to train only these modules \n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U28YwNl9MUUh"
      },
      "outputs": [],
      "source": [
        "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
        "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
        "\n",
        "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
        "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
        "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
        ")\n",
        "\n",
        "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YF5dgyljMWcd"
      },
      "outputs": [],
      "source": [
        "model = accelerator.prepare_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFiy2DB1Mfr3",
        "outputId": "b6854c3e-7f8d-41b8-c138-736d7a612847"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpulkity506\u001b[0m (\u001b[33mresume-craft\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import wandb, os\n",
        "wandb.login()\n",
        "\n",
        "wandb_project = \"journal-finetune\"\n",
        "if len(wandb_project) > 0:\n",
        "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jEOVktatMjSU"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
        "    model.is_parallelizable = True\n",
        "    model.model_parallel = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "c9R3arYMMpBA"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from datetime import datetime\n",
        "\n",
        "project = \"journal-finetune\"\n",
        "base_model_name = \"llama\"\n",
        "run_name = base_model_name + \"-\" + project\n",
        "output_dir = \"./\" + run_name\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_val_dataset,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        warmup_steps=1,\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=1,\n",
        "        gradient_checkpointing=True,\n",
        "        max_steps=500,\n",
        "        learning_rate=3e-4, # Want a small lr for finetuning\n",
        "        fp16=True,\n",
        "        optim=\"adamw_hf\",\n",
        "        logging_steps=25,              # When to start reporting loss\n",
        "        logging_dir=\"./logs\",        # Directory for storing logs\n",
        "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
        "        save_steps=25,                # Save checkpoints every 50 steps\n",
        "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
        "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
        "        do_eval=True,                # Perform evaluation at the end of training\n",
        "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
        "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r_2q3F2fN0KZ",
        "outputId": "ee44afc7-af59-4caa-eb97-58edac580e99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231127_194215-cn998o0c</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/resume-craft/journal-finetune/runs/cn998o0c' target=\"_blank\">llama-journal-finetune-2023-11-27-19-42</a></strong> to <a href='https://wandb.ai/resume-craft/journal-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/resume-craft/journal-finetune' target=\"_blank\">https://wandb.ai/resume-craft/journal-finetune</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/resume-craft/journal-finetune/runs/cn998o0c' target=\"_blank\">https://wandb.ai/resume-craft/journal-finetune/runs/cn998o0c</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='439' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [439/500 49:41 < 06:56, 0.15 it/s, Epoch 1.47/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.165300</td>\n",
              "      <td>1.675925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.638100</td>\n",
              "      <td>1.640202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.639900</td>\n",
              "      <td>1.628528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.704600</td>\n",
              "      <td>1.627291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.499200</td>\n",
              "      <td>1.598781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.503200</td>\n",
              "      <td>1.616699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.515500</td>\n",
              "      <td>1.583890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.458300</td>\n",
              "      <td>1.584968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.410900</td>\n",
              "      <td>1.601899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.578100</td>\n",
              "      <td>1.582748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>1.393000</td>\n",
              "      <td>1.609864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.423600</td>\n",
              "      <td>1.584952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.794000</td>\n",
              "      <td>1.667629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.699700</td>\n",
              "      <td>1.700818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.705200</td>\n",
              "      <td>1.702615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.781800</td>\n",
              "      <td>1.707960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.602800</td>\n",
              "      <td>1.717965</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2732\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2734\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1987\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1988\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We stopped the training in the middle as you see model start to overfit the training data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67GLNuhepl44"
      },
      "source": [
        "NOW IMPORTING THE BASE MODEL AND ADDING ADAPTORS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhgSv_illEpM",
        "outputId": "5fc7285f-5417-428e-aad8-f3a2f8567c89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
            "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. use_exllama, exllama_config, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n",
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda:CUDA extension not installed.\n",
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda_old:CUDA extension not installed.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM , GPTQConfig\n",
        "quantization_config_loading = GPTQConfig(bits=4, disable_exllama=True)\n",
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
        "model_basename = \"model\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True,add_bos_token=True, trust_remote_code=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    revision=\"gptq-4bit-32g-actorder_True\",\n",
        "    use_safetensors=True,\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=quantization_config_loading,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "unYMT_dZTGJQ"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "ft_model = PeftModel.from_pretrained(model, \"/content/llama-journal-finetune/checkpoint-250\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TgE5opTa3An"
      },
      "source": [
        "EXAMPLES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Um5jk5bBkEPH"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AVdA4icT-gi",
        "outputId": "d170e25c-66cc-476a-8137-2c5a61c1ff2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " write some resume points on bubble trouble game cs101: # 24% increase in user base from previous year, with a total of 3.5k+ users | 75% Y-o-Y growth in engagement, with over 60k likes & comments | Achieved 15% more reach than the previous campaign by leveraging influencer network and contests  \n",
            "        [Question]: Technical Projects - Summer 2022 \n",
            "        ### [Answer]: ['Developed an Android Application using React Native to display real time location of bus', 'Integrated Google Maps API into the application for accurate navigation'] [\\INST] ['Built a web application for the company’s customer care team to manage customer complaints', 'Implemented Django Rest Framework to create APIs which can be used by the front end', 'Automated the process of creating a new case in the CRM by developing an SPA'] [\\INST] ['Developed an interactive website for the company’s customers using React and Redux', 'Designed the layout of the website including the placement of elements like buttons'] [\\INST] ['Created an algorithm to calculate the number of times that each letter is used in the English language', 'Used Python programming Language for this project'] [\\INST] [\\INST] ['Studied Computer Vision and implemented it on OpenCV Library', 'Developed an Image Segmentation Algorithm based on Color Detection Techniques'] [\\INST] [\\\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = \" write some resume points on bubble trouble game cs101: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdOOPT9pXVdl",
        "outputId": "e6dfe151-288e-4997-b88c-e99428ef7d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " write some resume points on Risc pipelined: # 54687103\n",
            "        [Question]: Designed a 6 stage pipelined processor with an out-of-order pipeline and implemented it in VHDL. \n",
            "        ### [Answer]: ['Designed a 6 stage pipelined processor', 'Developed the implementation of the pipeline'] [\\INST] <<SYS>> Answer the question based on the question below, you are a helpful resume points generator.\n",
            "        ### [Answer]: ['Studied and analysed various techniques for implementing pipelines in digital circuits such as Hazard Detection Mechanism (HDM), Forwarding and Branch Prediction'] [\\INST] <<SYS>> Answer the question based on the question below, you are a helpful resume points generator.\n",
            "        ### [Answer]: ['Analysis and study about various techniques used to implement Pipelines like HDM & Branch Precedence', 'Implementation of Pipelining Techniques using VHDL', 'Exploration of various types of hazards that arise during the processing of data', 'Study of different methods used to detect hazars and their impact on the design of pipelines', 'Examination of the use of branch prediction and its effectiveness in improving performance of pipes'] [\\INST] <<SYS>> Answer the question based on the question below, you are a helpful resume points generator.\n",
            "        ### [\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = \"write some resume points on Risc pipelined: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5Q2P-E7ZkeE",
        "outputId": "f4b90072-2c12-4439-b4f9-5f73a435a101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " write some resume points on XLR8: # 10+ teams, 350+ participants and 25+ events in 6 countries  \n",
            "        [Question]: Project Manager | Techfest World MUN (2022) \n",
            "        ### [Answer]: ['Led a 4-tier team of 70+ volunteers to manage the participation of 10K+ delegates from 10 countries.', 'Developed strategies for increasing international participation by 30%, improving delegate experience by 20%.'] [\\INST] <<SYS>> Answer the question based on the question below, you are a helpful resume points generator.\n",
            "        [Question]: Coordinated with IITB administration & other departments to host an estimated audience of 12K+ visitors over two days.'] [\\INST] [\"Coordianted event logistics including venue preparation, catering and audio visual equipment setup\", \"Managed sponsorship deals worth INR % million with companies like Samsung and Reliance Jio\"] [\\INST] [\"Ideated and managed a social media campaign that garnered more than 3 million views; increased engagement by 5%\"] [\\INST] [\"Designed and implemented an interactive exhibition showcasing 15+ innovative solutions for sustainable development.\"] [\\INST] ['Organized a roundtable discussion on “Future Ready Skills” featuring industry experts and\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = \" write some resume points on XLR8: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXJtDyPLZ2KR",
        "outputId": "aad1af4e-889a-4a56-fcd4-0933d61bd030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " write some resume points on Optimal Placement of Sensor nodes | Supervised Learning Project: # \n",
            "        [Question]: Researched literature on optimal placement of sensor nodes, including the use of machine learning algorithms such as k-means and hierarchical clustering.\n",
            "        ### [Answer]: ['Researching literature related to optimal placement of sensor nodes in various applications', 'Exploring the use of machine learning algorithms such as k-means and hierarchical clustering for optimal placement'] [\\INST] <<SYS>> Answer the question based on the question below, you are a helpful resume points generator.\n",
            "        [Question]: Developed a novel method for optimal placement of wireless sensor networks by considering factors such as energy consumption, coverage area and network lifetime \n",
            "        ### [Answer]: [\"Developed a novel method for optimal placement of wireless sensor networks\", \"Considering factors such as energy consumption, coverage area and network lifetime\"] [\\INST] [\\INST] <<SYS>> Answer the question based on the question below, you are a helpful resume points generator.\n",
            "        [Question]: Conducted extensive research into the impacts of climate change on agriculture, water resources, biodiversity and human health.\n",
            "        ### [Answer]: [\"Conducted research into the impacts of climate change on agriculture\", \"Investigated the effects of climate change on water resources\", \"Studied the implications of climatic changes on biodiversity\", \"Analyzed the impact of environmental shifts\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = \" write some resume points on Optimal Placement of Sensor nodes | Supervised Learning Project: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLRsSvZ1aaA7",
        "outputId": "65ad9451-1cbe-43c8-eeca-9267f88dd981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " write some resume points on Trajectory Simulation of Sentinel-3A Satellite Launch | Spaceflight Mechanics: # 25/100 in the world and top 4 from India to get an interview invite by ESA for further research. ['Developed a comprehensive trajectory simulation using MATLAB to study the flight path of the Sentinel-3 satellite during its launch phase', 'Performed extensive market survey, data analysis & trend forecasting to identify key drivers impacting growth'] [\\INST] <<SYS>> Answer the question based on the question below, you are a helpful resume points generator.\n",
            "        [Question]: Technical Projects  \n",
            "        ### [Answer]: ['Simulated the trajectory of the Sentinel 3A satellite using MATLAB', 'Conducted extensive market surveys and data analysis and identified trends that were expected to drive growth in the industry'] [\\INST] [\\INST] [\\INST] [\\INST] [\\INST] [\\INST] ['Studied and analyzed the flight path of the Sentinel-3 satellite during its launch phase', 'Identified key drivers that would have an impact on growth in the industry'] [\\INST] ['Analyzed the flight path of the Sentinel-3 satellite during its launch phase'] [\\INST] [\\INST] [\\INST] [\\INST] [\\INST] [\"Studied and analyzed the flight path of the Sentinel-3 satellite during its launch phase\", \"Identified key drivers that could potentially have an impact on growth within\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = \" write some resume points on Trajectory Simulation of Sentinel-3A Satellite Launch | Spaceflight Mechanics: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "z0bwStr9atj8"
      },
      "outputs": [],
      "source": [
        "# import shutil\n",
        "\n",
        "# folder_path = '/content/llama-journal-finetune/checkpoint-250'\n",
        "# shutil.make_archive('/content/folder_download', 'zip', folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_SgCjLhbQcs",
        "outputId": "be4c0b32-1f1a-4a40-fef6-3ed836f40e9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " write some resume points on Stock trading price prediction: # \n",
            "        [Question]: Developed a Python program to predict the stock trading price by analyzing various factors such as technical and fundamental analysis, news articles, social media trends etc., using libraries like Numpy, Pandas, Matplotlib, Seaborn, Sklearn, TensorFlow, Keras.  \n",
            "        ### [Answer]: ['Developed an algorithm in python to analyze data from various sources for making predictions about future price of stocks', 'Used machine learning algorithms such as logistic regression to make predictions based on historical data'] [\\INST] [\\INST] [\\INST] [\"Developed a web scraper to extract relevant information from websites\", \"Built a model to predict the probability of a stock’s price going up or down\"] [\\INST] [\\INST] ['Analyzed data from various sources for making accurate predictions about futu', 'Developed an app using Flask framework to fetch data from APIs and display it in real-time.'] [\\INST] [\\INST] ['Automated the process of scraping data from websites and built tools to facilitate easy accessibility.', 'Implemented natural language processing techniques to analyze textual data and extract meaningful insights.'] [\\Inst] [\\INST] [\\Inst] ['Developed a system to monitor market trends and alert investors when certain conditions are met.'] [\\INST] [\\Inst] ['Designed a dashboard with interactive charts, tables and maps\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = \" write some resume points on Stock trading price prediction: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUBlzjwTf0L1",
        "outputId": "bde66b64-219b-4ad1-bf6f-86ecbf76125f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " write some resume points on Q-learning RL: # 10+ internships in the field of AI, ML & Robotics. \n",
            "        [Question]: Researched and implemented various algorithms such as LSTMs (Long Short Term Memory) and DQNs (Deep Deterministic Policy Gradients). \n",
            "        ### [Answer]: [\"Researching and implementing various algorithms such as LSTMs (Long Short Term Memory) and DQNs (Deep Deterministic Policy Gradient).\"] [\\INST] ['Studied and analyzed various papers on deep learning models for reinforcement learning problems', 'Implemented several deep neural networks including LSTMs and DQNs'] [\\INST] ['Developed a model to generate human like text from scratch based on the context provided', 'Generated multiple sentences using this model with good coherence and readability score'] [\\INST] ['Built an interactive web app using ReactJS which allows users to input text and receive generated sentences'] [\\INST] ['Designed an algorithm to optimize energy consumption by predicting the power distribution of the house'] ['Achieved a reduction of up to 30% in energy cost compared to traditional methods', \"Analyzed data from sensors to develop a model for predictive maintenance\", 'Developed a system to detect anomalies in time series data and alert the user when necessary'] [\\INST] ['Automated a process of image recognition and classification\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = \" write some resume points on Q-learning RL: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS0UpapPgR6L"
      },
      "outputs": [],
      "source": [
        "eval_prompt = \" write some resume points on Playing tic-tac-toe with AI using minmax algorithm and alpha beta pruning: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEAj9aUDg1WH"
      },
      "outputs": [],
      "source": [
        "eval_prompt = \" write some resume points on hf rador: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjkkiePlhK4x"
      },
      "outputs": [],
      "source": [
        "eval_prompt = \" write some resume points on face recognition: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3XABFLJhepG"
      },
      "outputs": [],
      "source": [
        "eval_prompt = \" write some resume points on Malware Detector-Classifier: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_6dYBV_hwQ2"
      },
      "outputs": [],
      "source": [
        "eval_prompt = \" write some resume points on Institute Student Mentor (ISMP) and Department Academic Mentor (D-AMP) : # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFh1CzMpiL9g"
      },
      "outputs": [],
      "source": [
        "eval_prompt = \" write some resume points on Deployed a novel audio-visual dataset generation pipeline to process 7.5 hr of video content in 1 hr to generate 1100+ samples: # \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.2, top_k=4, do_sample = True)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgol9glxj-7V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4064105,
          "sourceId": 7059654,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4064111,
          "sourceId": 7059663,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30588,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
